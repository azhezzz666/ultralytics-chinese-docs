---
comments: true
description: 探索测试计算机视觉模型的有效方法，以确保它们可靠、性能良好并准备好部署。
keywords: 机器学习中的过拟合和欠拟合, 模型测试, 数据泄漏机器学习, 测试模型, 测试机器学习模型, 如何测试 AI 模型
---

# 模型测试指南

## 简介

在[训练](./model-training-tips.md)和[评估](./model-evaluation-insights.md)模型之后，是时候测试它了。模型测试涉及评估它在真实世界场景中的表现。测试考虑准确性、可靠性、公平性以及理解模型决策的难易程度等因素。目标是确保模型按预期执行，提供预期结果，并符合您的应用或项目的[整体目标](./defining-project-goals.md)。

<p align="center">
  <br>
  <iframe loading="lazy" width="720" height="405" src="https://www.youtube.com/embed/SyyCUvxw9BM"
    title="YouTube video player" frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
  <br>
  <strong>观看：</strong> 如何测试机器学习模型 | 避免计算机视觉中的数据泄漏 🚀
</p>

模型测试与模型评估非常相似，但它们是[计算机视觉项目中的两个不同步骤](./steps-of-a-cv-project.md)。模型评估涉及使用指标和图表来评估模型的准确性。另一方面，模型测试检查模型学习到的行为是否与预期相同。在本指南中，我们将探讨测试[计算机视觉](https://www.ultralytics.com/glossary/computer-vision-cv)模型的策略。

## 模型测试与模型评估

首先，让我们通过一个例子来理解模型评估和测试之间的区别。

假设您训练了一个计算机视觉模型来识别猫和狗，并且您想在宠物店部署这个模型来监控动物。在模型评估阶段，您使用标记的数据集来计算准确率、[精确率](https://www.ultralytics.com/glossary/precision)、[召回率](https://www.ultralytics.com/glossary/recall)和 F1 分数等指标。例如，模型在给定数据集中区分猫和狗的准确率可能为 98%。

评估后，您使用宠物店的图像测试模型，看看它在更多样化和真实的条件下识别猫和狗的效果如何。您检查它是否能在动物移动、不同光照条件下或被玩具或家具等物体部分遮挡时正确标记猫和狗。模型测试检查模型在受控评估环境之外是否按预期行为。

## 准备模型测试

计算机视觉模型通过检测模式、进行预测和评估其性能来从数据集中学习。这些[数据集](./preprocessing_annotated_data.md)通常分为训练集和测试集以模拟真实世界条件。[训练数据](https://www.ultralytics.com/glossary/training-data)教导模型，而测试数据验证其准确性。

在测试模型之前，请记住以下两点：

- **真实代表性**：之前未见过的测试数据应与模型部署时必须处理的数据相似。这有助于真实了解模型的能力。
- **足够的大小**：测试数据集的大小需要足够大，以提供关于模型性能的可靠见解。

## 测试您的计算机视觉模型

以下是测试计算机视觉模型并了解其性能的关键步骤。

- **运行预测**：使用模型对测试数据集进行预测。
- **比较预测**：检查模型的预测与实际标签（真实值）的匹配程度。
- **计算性能指标**：[计算指标](./yolo-performance-metrics.md)如准确率、精确率、召回率和 F1 分数，以了解模型的优势和劣势。测试侧重于这些指标如何反映真实世界的性能。
- **可视化结果**：创建混淆矩阵和 ROC 曲线等可视化辅助工具。这些帮助您发现模型在实际应用中可能表现不佳的特定领域。

接下来，可以分析测试结果：

- **错误分类的图像**：识别和审查模型错误分类的图像，以了解它在哪里出错。
- **错误分析**：进行彻底的错误分析，以了解错误的类型（例如，假阳性与假阴性）及其潜在原因。
- **偏差和公平性**：检查模型预测中的任何偏差。确保模型在数据的不同子集上表现同样好，特别是如果它包含种族、性别或年龄等敏感属性。

## 测试您的 YOLO11 模型

要测试您的 YOLO11 模型，您可以使用验证模式。这是了解模型优势和需要改进领域的直接方法。此外，您需要为 YOLO11 正确格式化测试数据集。有关如何使用验证模式的更多详情，请查看[模型验证](../modes/val.md)文档页面。

## 使用 YOLO11 对多个测试图像进行预测

如果您想在存储在文件夹中的多个图像上测试训练好的 YOLO11 模型，您可以一次性轻松完成。与通常用于评估验证集上模型性能并提供详细指标的验证模式不同，您可能只想查看测试集中所有图像的预测。为此，您可以使用[预测模式](../modes/predict.md)。

### 验证模式和预测模式之间的区别

- **[验证模式](../modes/val.md)**：用于通过将预测与已知标签（真实值）进行比较来评估模型的性能。它提供详细的指标，如准确率、精确率、召回率和 F1 分数。
- **[预测模式](../modes/predict.md)**：用于在新的、未见过的数据上运行模型以生成预测。它不提供详细的性能指标，但允许您查看模型在真实世界图像上的表现。

## 在没有自定义训练的情况下运行 YOLO11 预测

如果您有兴趣测试基本的 YOLO11 模型，以了解它是否可以在没有自定义训练的情况下用于您的应用，您可以使用预测模式。虽然模型是在 COCO 等数据集上预训练的，但在您自己的数据集上运行预测可以让您快速了解它在您的特定环境中可能表现如何。

## [机器学习](https://www.ultralytics.com/glossary/machine-learning-ml)中的过拟合和[欠拟合](https://www.ultralytics.com/glossary/underfitting)

在测试机器学习模型时，特别是在计算机视觉中，注意过拟合和欠拟合很重要。这些问题可能会显著影响模型处理新数据的效果。

### 过拟合

当模型对训练数据学习得太好时，就会发生过拟合，包括不能泛化到新数据的噪声和细节。在计算机视觉中，这意味着您的模型可能在训练图像上表现很好，但在新图像上表现不佳。

#### 过拟合的迹象

- **高训练准确率，低验证准确率**：如果您的模型在训练数据上表现非常好，但在验证或[测试数据](https://www.ultralytics.com/glossary/test-data)上表现不佳，它可能过拟合了。
- **视觉检查**：有时，如果您的模型对图像中的微小变化或无关细节过于敏感，您可以看到过拟合。

### 欠拟合

当模型无法捕获数据中的底层模式时，就会发生欠拟合。在计算机视觉中，欠拟合的模型甚至可能无法正确识别训练图像中的对象。

#### 欠拟合的迹象

- **低训练准确率**：如果您的模型无法在训练集上达到高准确率，它可能欠拟合了。
- **视觉错误分类**：持续无法识别明显的特征或对象表明欠拟合。

### 平衡过拟合和欠拟合

关键是在过拟合和欠拟合之间找到平衡。理想情况下，模型应该在训练和验证数据集上都表现良好。通过指标和视觉检查定期监控模型的性能，以及应用正确的策略，可以帮助您获得最佳结果。

<p align="center">
  <img width="100%" src="https://github.com/ultralytics/docs/releases/download/0/overfitting-underfitting-appropriate-fitting.avif" alt="过拟合和欠拟合概述">
</p>

## 计算机视觉中的数据泄漏及如何避免

在测试模型时，需要记住的一件重要事情是数据泄漏。当训练数据集之外的信息意外地被用于训练模型时，就会发生数据泄漏。当数据泄漏发生时，模型在训练期间可能看起来非常准确，但在新的、未见过的数据上表现不佳。

### 为什么会发生数据泄漏

数据泄漏可能很难发现，通常来自训练数据中的隐藏偏差。以下是计算机视觉中可能发生的一些常见方式：

- **相机偏差**：不同的角度、光照、阴影和相机移动可能会引入不需要的模式。
- **叠加偏差**：图像中的徽标、时间戳或其他叠加可能会误导模型。
- **字体和对象偏差**：经常出现在某些类别中的特定字体或对象可能会扭曲模型的学习。
- **空间偏差**：前景-背景、[边界框](https://www.ultralytics.com/glossary/bounding-box)分布和对象位置的不平衡可能会影响训练。
- **标签和领域偏差**：不正确的标签或数据类型的变化可能导致泄漏。

### 检测数据泄漏

要发现数据泄漏，您可以：

- **检查性能**：如果模型的结果出奇地好，它可能正在泄漏。
- **查看特征重要性**：如果一个特征比其他特征重要得多，它可能表明泄漏。
- **视觉检查**：仔细检查模型的决策是否直观上有意义。
- **验证数据分离**：确保在任何处理之前数据被正确划分。

### 避免数据泄漏

为了防止数据泄漏，使用来自不同相机和环境的图像或视频的多样化数据集。仔细审查您的数据并检查是否存在隐藏的偏差，例如所有正样本都在一天中的特定时间拍摄。避免数据泄漏将有助于使您的计算机视觉模型在真实世界情况下更加可靠和有效。

## 模型测试后的下一步

测试模型后，下一步取决于结果。如果您的模型表现良好，您可以将其部署到真实世界环境中。如果结果不令人满意，您需要进行改进。这可能涉及分析错误、[收集更多数据](./data-collection-and-annotation.md)、提高数据质量、[调整超参数](./hyperparameter-tuning.md)和重新训练模型。

## 加入 AI 对话

成为计算机视觉爱好者社区的一部分可以帮助解决问题并更有效地学习。以下是一些连接、寻求帮助和分享想法的方式。

### 社区资源

- **GitHub Issues**：探索 [YOLO11 GitHub 仓库](https://github.com/ultralytics/ultralytics/issues)并使用 Issues 标签提问、报告错误和建议新功能。社区和维护者非常活跃，随时准备提供帮助。
- **Ultralytics Discord 服务器**：加入 [Ultralytics Discord 服务器](https://discord.com/invite/ultralytics)与其他用户和开发者聊天，获得支持并分享您的经验。

### 官方文档

- **Ultralytics YOLO11 文档**：查看[官方 YOLO11 文档](./index.md)获取各种计算机视觉项目的详细指南和有用技巧。

这些资源将帮助您应对挑战并了解计算机视觉社区的最新趋势和实践。

## 总结

构建可信赖的计算机视觉模型依赖于严格的模型测试。通过使用之前未见过的数据测试模型，我们可以分析它并发现[过拟合](https://www.ultralytics.com/glossary/overfitting)和数据泄漏等弱点。在部署之前解决这些问题有助于模型在真实世界应用中表现良好。重要的是要记住，模型测试与模型评估一样重要，以保证模型的长期成功和有效性。

## 常见问题

### 计算机视觉中模型评估和模型测试之间的主要区别是什么？

模型评估和模型测试是计算机视觉项目中的不同步骤。模型评估涉及使用标记的数据集来计算[准确率](https://www.ultralytics.com/glossary/accuracy)、精确率、召回率和 [F1 分数](https://www.ultralytics.com/glossary/f1-score)等指标，提供关于模型在受控数据集上性能的见解。另一方面，模型测试通过将模型应用于新的、未见过的数据来评估模型在真实世界场景中的性能，确保模型学习到的行为与评估环境之外的预期一致。有关详细指南，请参阅[计算机视觉项目中的步骤](./steps-of-a-cv-project.md)。

### 如何在多个图像上测试我的 Ultralytics YOLO11 模型？

要在多个图像上测试您的 Ultralytics YOLO11 模型，您可以使用[预测模式](../modes/predict.md)。此模式允许您在新的、未见过的数据上运行模型以生成预测，而无需提供详细的指标。这非常适合在存储在文件夹中的较大图像集上进行真实世界性能测试。要评估性能指标，请改用[验证模式](../modes/val.md)。

### 如果我的计算机视觉模型显示过拟合或欠拟合的迹象，我应该怎么做？

解决**过拟合**：

- [正则化](https://www.ultralytics.com/glossary/regularization)技术如 dropout。
- 增加训练数据集的大小。
- 简化模型架构。

解决**欠拟合**：

- 使用更复杂的模型。
- 提供更多相关特征。
- 增加训练迭代或[轮次](https://www.ultralytics.com/glossary/epoch)。

审查错误分类的图像，进行彻底的错误分析，并定期跟踪性能指标以保持平衡。有关这些概念的更多信息，请探索我们关于[过拟合和欠拟合](#机器学习中的过拟合和欠拟合)的部分。

### 如何检测和避免计算机视觉中的数据泄漏？

检测数据泄漏：

- 验证测试性能是否异常高。
- 检查特征重要性是否有意外的见解。
- 直观地审查模型决策。
- 确保在处理之前正确划分数据。

避免数据泄漏：

- 使用来自各种环境的多样化数据集。
- 仔细审查数据是否存在隐藏偏差。
- 确保训练集和测试集之间没有重叠信息。

有关防止数据泄漏的详细策略，请参阅我们关于[计算机视觉中的数据泄漏](#计算机视觉中的数据泄漏及如何避免)的部分。

### 测试计算机视觉模型后应该采取哪些步骤？

测试后，如果模型性能达到项目目标，则继续部署。如果结果不令人满意，请考虑：

- 错误分析。
- 收集更多多样化和高质量的数据。
- [超参数调优](https://www.ultralytics.com/glossary/hyperparameter-tuning)。
- 重新训练模型。

从[模型测试与模型评估](#模型测试与模型评估)部分获取见解，以优化和增强模型在真实世界应用中的有效性。

### 如何在没有自定义训练的情况下运行 YOLO11 预测？

您可以使用预训练的 YOLO11 模型在您的数据集上运行预测，以查看它是否适合您的应用需求。利用[预测模式](../modes/predict.md)快速了解性能结果，而无需深入自定义训练。
