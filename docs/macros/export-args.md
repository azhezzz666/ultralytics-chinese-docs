| 参数        | 类型              | 默认值          | 描述                                                                                                                                                                                                                                                                                                                                                       |
| ----------- | ----------------- | --------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `format`    | `str`             | `'torchscript'` | 导出模型的目标格式，如 `'onnx'`、`'torchscript'`、`'engine'`（TensorRT）或其他格式。每种格式都支持与不同[部署环境](https://docs.ultralytics.com/modes/export/)的兼容性。                                                                                                                                                                                    |
| `imgsz`     | `int` 或 `tuple`  | `640`           | 模型输入所需的图像尺寸。可以是整数用于正方形图像（例如 `640` 表示 640×640）或元组 `(height, width)` 用于特定尺寸。                                                                                                                                                                                                                                          |
| `keras`     | `bool`            | `False`         | 启用导出为 Keras 格式以用于 [TensorFlow](https://www.ultralytics.com/glossary/tensorflow) SavedModel，提供与 TensorFlow serving 和 API 的兼容性。                                                                                                                                                                                                          |
| `optimize`  | `bool`            | `False`         | 导出到 TorchScript 时应用移动设备优化，可能减小模型大小并提高[推理](https://docs.ultralytics.com/modes/predict/)性能。不兼容 NCNN 格式或 CUDA 设备。                                                                                                                                                                                                        |
| `half`      | `bool`            | `False`         | 启用 FP16（半精度）量化，减小模型大小并可能在支持的硬件上加速推理。不兼容 INT8 量化或仅 CPU 导出。仅适用于某些格式，例如 ONNX（见下文）。                                                                                                                                                                                                                   |
| `int8`      | `bool`            | `False`         | 激活 INT8 量化，进一步压缩模型并加速推理，同时[精度](https://www.ultralytics.com/glossary/accuracy)损失最小，主要用于[边缘设备](https://www.ultralytics.com/blog/understanding-the-real-world-applications-of-edge-ai)。与 TensorRT 一起使用时，执行训练后量化（PTQ）。                                                                                    |
| `dynamic`   | `bool`            | `False`         | 允许 ONNX、TensorRT 和 OpenVINO 导出使用动态输入尺寸，增强处理不同图像尺寸的灵活性。使用带 INT8 的 TensorRT 时自动设置为 `True`。                                                                                                                                                                                                                           |
| `simplify`  | `bool`            | `True`          | 使用 `onnxslim` 简化 ONNX 导出的模型图，可能提高性能和与推理引擎的兼容性。                                                                                                                                                                                                                                                                                  |
| `opset`     | `int`             | `None`          | 指定 ONNX opset 版本以兼容不同的 [ONNX](https://docs.ultralytics.com/integrations/onnx/) 解析器和运行时。如果未设置，使用最新支持的版本。                                                                                                                                                                                                                   |
| `workspace` | `float` 或 `None` | `None`          | 设置 [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) 优化的最大工作空间大小（GiB），平衡内存使用和性能。使用 `None` 让 TensorRT 自动分配到设备最大值。                                                                                                                                                                                      |
| `nms`       | `bool`            | `False`         | 在支持时向导出的模型添加非极大值抑制（NMS）（参见[导出格式](https://docs.ultralytics.com/modes/export/)），提高检测后处理效率。不适用于 end2end 模型。                                                                                                                                                                                                      |
| `batch`     | `int`             | `1`             | 指定导出模型的批量推理大小或导出模型在 `predict` 模式下并发处理的最大图像数。对于 Edge TPU 导出，此值自动设置为 1。                                                                                                                                                                                                                                         |
| `device`    | `str`             | `None`          | 指定导出设备：GPU（`device=0`）、CPU（`device=cpu`）、Apple silicon 的 MPS（`device=mps`）或 NVIDIA Jetson 的 DLA（`device=dla:0` 或 `device=dla:1`）。TensorRT 导出自动使用 GPU。                                                                                                                                                                          |
| `data`      | `str`             | `'coco8.yaml'`  | [数据集](https://docs.ultralytics.com/datasets/)配置文件的路径（默认：`coco8.yaml`），对 INT8 量化校准至关重要。如果启用 INT8 但未指定，将分配默认数据集。                                                                                                                                                                                                  |
| `fraction`  | `float`           | `1.0`           | 指定用于 INT8 量化校准的数据集比例。允许在完整数据集的子集上进行校准，适用于实验或资源有限的情况。如果启用 INT8 但未指定，将使用完整数据集。                                                                                                                                                                                                                |
