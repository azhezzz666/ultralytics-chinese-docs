# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from __future__ import annotations

import argparse

import cv2
import numpy as np
import onnxruntime as ort
import torch

from ultralytics.engine.results import Results
from ultralytics.utils import ASSETS, YAML, nms, ops
from ultralytics.utils.checks import check_yaml


class YOLOv8Seg:
    """ä½¿ç”¨ ONNX Runtime æ‰§è¡Œå®ä¾‹åˆ†å‰²çš„ YOLOv8 åˆ†å‰²æ¨¡å‹ã€‚

    è¯¥ç±»ä½¿ç”¨ ONNX Runtime å®ç° YOLOv8 å®ä¾‹åˆ†å‰²æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚å®ƒå¤„ç†è¾“å…¥å›¾åƒçš„é¢„å¤„ç†ã€
    ä½¿ç”¨ ONNX æ¨¡å‹è¿è¡Œæ¨ç†ï¼Œä»¥åŠåå¤„ç†ç»“æœä»¥ç”Ÿæˆè¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç ã€‚

    Attributes:
        session (ort.InferenceSession): ç”¨äºæ¨¡å‹æ‰§è¡Œçš„ ONNX Runtime æ¨ç†ä¼šè¯ã€‚
        imgsz (tuple[int, int]): æ¨¡å‹çš„è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œæ ¼å¼ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚
        classes (dict): å°†ç±»åˆ«ç´¢å¼•æ˜ å°„åˆ°æ•°æ®é›†ç±»åˆ«åç§°çš„å­—å…¸ã€‚
        conf (float): è¿‡æ»¤æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚
        iou (float): éæå¤§å€¼æŠ‘åˆ¶ä½¿ç”¨çš„ IoU é˜ˆå€¼ã€‚

    Methods:
        letterbox: åœ¨ä¿æŒå®½é«˜æ¯”çš„åŒæ—¶è°ƒæ•´å’Œå¡«å……å›¾åƒã€‚
        preprocess: åœ¨è¾“å…¥æ¨¡å‹ä¹‹å‰é¢„å¤„ç†è¾“å…¥å›¾åƒã€‚
        postprocess: åå¤„ç†æ¨¡å‹é¢„æµ‹ä»¥æå–æœ‰æ„ä¹‰çš„ç»“æœã€‚
        process_mask: ä½¿ç”¨é¢„æµ‹çš„æ©ç ç³»æ•°å¤„ç†åŸå‹æ©ç ä»¥ç”Ÿæˆå®ä¾‹åˆ†å‰²æ©ç ã€‚

    Examples:
        >>> model = YOLOv8Seg("yolov8n-seg.onnx", conf=0.25, iou=0.7)
        >>> img = cv2.imread("image.jpg")
        >>> results = model(img)
        >>> cv2.imshow("Segmentation", results[0].plot())
    """

    def __init__(self, onnx_model: str, conf: float = 0.25, iou: float = 0.7, imgsz: int | tuple[int, int] = 640):
        """ä½¿ç”¨ ONNX æ¨¡å‹åˆå§‹åŒ–å®ä¾‹åˆ†å‰²æ¨¡å‹ã€‚

        Args:
            onnx_model (str): ONNX æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ã€‚
            conf (float, optional): è¿‡æ»¤æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚
            iou (float, optional): éæå¤§å€¼æŠ‘åˆ¶çš„ IoU é˜ˆå€¼ã€‚
            imgsz (int | tuple[int, int], optional): æ¨¡å‹çš„è¾“å…¥å›¾åƒå°ºå¯¸ã€‚å¯ä»¥æ˜¯æ•´æ•°ï¼ˆæ­£æ–¹å½¢è¾“å…¥ï¼‰
                æˆ–å…ƒç»„ï¼ˆçŸ©å½¢è¾“å…¥ï¼‰ã€‚
        """
        available = ort.get_available_providers()
        providers = [p for p in ("CUDAExecutionProvider", "CPUExecutionProvider") if p in available]
        self.session = ort.InferenceSession(onnx_model, providers=providers or available)

        self.imgsz = (imgsz, imgsz) if isinstance(imgsz, int) else imgsz
        self.classes = YAML.load(check_yaml("coco8.yaml"))["names"]
        self.conf = conf
        self.iou = iou

    def __call__(self, img: np.ndarray) -> list[Results]:
        """ä½¿ç”¨ ONNX æ¨¡å‹å¯¹è¾“å…¥å›¾åƒè¿è¡Œæ¨ç†ã€‚

        Args:
            img (np.ndarray): BGR æ ¼å¼çš„åŸå§‹è¾“å…¥å›¾åƒã€‚

        Returns:
            (list[Results]): åå¤„ç†åçš„æ£€æµ‹ç»“æœï¼ŒåŒ…å«è¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç ã€‚
        """
        prep_img = self.preprocess(img, self.imgsz)
        outs = self.session.run(None, {self.session.get_inputs()[0].name: prep_img})
        return self.postprocess(img, prep_img, outs)

    def letterbox(self, img: np.ndarray, new_shape: tuple[int, int] = (640, 640)) -> np.ndarray:
        """åœ¨ä¿æŒå®½é«˜æ¯”çš„åŒæ—¶è°ƒæ•´å’Œå¡«å……å›¾åƒã€‚

        Args:
            img (np.ndarray): BGR æ ¼å¼çš„è¾“å…¥å›¾åƒã€‚
            new_shape (tuple[int, int], optional): ç›®æ ‡å½¢çŠ¶ï¼Œæ ¼å¼ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚

        Returns:
            (np.ndarray): è°ƒæ•´å¤§å°å¹¶å¡«å……åçš„å›¾åƒã€‚
        """
        shape = img.shape[:2]  # å½“å‰å½¢çŠ¶ [é«˜åº¦, å®½åº¦]

        # ç¼©æ”¾æ¯”ä¾‹ï¼ˆæ–° / æ—§ï¼‰
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])

        # è®¡ç®—å¡«å……
        new_unpad = round(shape[1] * r), round(shape[0] * r)
        dw, dh = (new_shape[1] - new_unpad[0]) / 2, (new_shape[0] - new_unpad[1]) / 2  # å®½é«˜å¡«å……

        if shape[::-1] != new_unpad:  # è°ƒæ•´å¤§å°
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
        top, bottom = round(dh - 0.1), round(dh + 0.1)
        left, right = round(dw - 0.1), round(dw + 0.1)
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))

        return img

    def preprocess(self, img: np.ndarray, new_shape: tuple[int, int]) -> np.ndarray:
        """åœ¨è¾“å…¥æ¨¡å‹ä¹‹å‰é¢„å¤„ç†è¾“å…¥å›¾åƒã€‚

        Args:
            img (np.ndarray): BGR æ ¼å¼çš„è¾“å…¥å›¾åƒã€‚
            new_shape (tuple[int, int]): è°ƒæ•´å¤§å°çš„ç›®æ ‡å½¢çŠ¶ï¼Œæ ¼å¼ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚

        Returns:
            (np.ndarray): å‡†å¤‡å¥½è¿›è¡Œæ¨¡å‹æ¨ç†çš„é¢„å¤„ç†å›¾åƒï¼Œå½¢çŠ¶ä¸º (1, 3, height, width)ï¼Œ
                å½’ä¸€åŒ–åˆ° [0, 1]ã€‚
        """
        img = self.letterbox(img, new_shape)
        img = img[..., ::-1].transpose([2, 0, 1])[None]  # BGR è½¬ RGBï¼ŒBHWC è½¬ BCHW
        img = np.ascontiguousarray(img)
        img = img.astype(np.float32) / 255  # å½’ä¸€åŒ–åˆ° [0, 1]
        return img

    def postprocess(self, img: np.ndarray, prep_img: np.ndarray, outs: list) -> list[Results]:
        """åå¤„ç†æ¨¡å‹é¢„æµ‹ä»¥æå–æœ‰æ„ä¹‰çš„ç»“æœã€‚

        Args:
            img (np.ndarray): åŸå§‹è¾“å…¥å›¾åƒã€‚
            prep_img (np.ndarray): ç”¨äºæ¨ç†çš„é¢„å¤„ç†å›¾åƒã€‚
            outs (list): åŒ…å«é¢„æµ‹å’ŒåŸå‹æ©ç çš„æ¨¡å‹è¾“å‡ºã€‚

        Returns:
            (list[Results]): åŒ…å«è¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç çš„å¤„ç†åæ£€æµ‹ç»“æœã€‚
        """
        preds, protos = (torch.from_numpy(p) for p in outs)
        preds = nms.non_max_suppression(preds, self.conf, self.iou, nc=len(self.classes))

        results = []
        for i, pred in enumerate(preds):
            pred[:, :4] = ops.scale_boxes(prep_img.shape[2:], pred[:, :4], img.shape)
            masks = self.process_mask(protos[i], pred[:, 6:], pred[:, :4], img.shape[:2])
            results.append(Results(img, path="", names=self.classes, boxes=pred[:, :6], masks=masks))

        return results

    def process_mask(
        self, protos: torch.Tensor, masks_in: torch.Tensor, bboxes: torch.Tensor, shape: tuple[int, int]
    ) -> torch.Tensor:
        """ä½¿ç”¨é¢„æµ‹çš„æ©ç ç³»æ•°å¤„ç†åŸå‹æ©ç ä»¥ç”Ÿæˆå®ä¾‹åˆ†å‰²æ©ç ã€‚

        Args:
            protos (torch.Tensor): å½¢çŠ¶ä¸º (mask_dim, mask_h, mask_w) çš„åŸå‹æ©ç ã€‚
            masks_in (torch.Tensor): å½¢çŠ¶ä¸º (N, mask_dim) çš„é¢„æµ‹æ©ç ç³»æ•°ï¼Œå…¶ä¸­ N æ˜¯æ£€æµ‹æ•°é‡ã€‚
            bboxes (torch.Tensor): å½¢çŠ¶ä¸º (N, 4) çš„è¾¹ç•Œæ¡†ï¼Œå…¶ä¸­ N æ˜¯æ£€æµ‹æ•°é‡ã€‚
            shape (tuple[int, int]): è¾“å…¥å›¾åƒçš„å°ºå¯¸ï¼Œæ ¼å¼ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚

        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (N, height, width) çš„äºŒå€¼åˆ†å‰²æ©ç ã€‚
        """
        c, mh, mw = protos.shape  # CHW
        masks = (masks_in @ protos.float().view(c, -1)).view(-1, mh, mw)  # çŸ©é˜µä¹˜æ³•
        masks = ops.scale_masks(masks[None], shape)[0]  # å°†æ©ç ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸
        masks = ops.crop_mask(masks, bboxes)  # å°†æ©ç è£å‰ªåˆ°è¾¹ç•Œæ¡†
        return masks.gt_(0.0)  # è½¬æ¢ä¸ºäºŒå€¼æ©ç 


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, required=True, help="ONNX æ¨¡å‹çš„è·¯å¾„")
    parser.add_argument("--source", type=str, default=str(ASSETS / "bus.jpg"), help="è¾“å…¥å›¾åƒçš„è·¯å¾„")
    parser.add_argument("--conf", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--iou", type=float, default=0.7, help="NMS IoU é˜ˆå€¼")
    args = parser.parse_args()

    model = YOLOv8Seg(args.model, args.conf, args.iou)
    img = cv2.imread(args.source)
    results = model(img)

    cv2.imshow("Segmented Image", results[0].plot())
    cv2.waitKey(0)
    cv2.destroyAllWindows()
